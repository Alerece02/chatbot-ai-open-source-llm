# ğŸ¥ Assistente Virtuale Sanitario

## ğŸ“‹ Descrizione Progetto

Assistente virtuale basato su AI per facilitare l'accesso alle informazioni.

### ğŸ¯ Obiettivi
- **AccessibilitÃ **: Rendere le informazioni sanitarie facilmente accessibili, specialmente per anziani
- **Privacy**: Tutto rimane on-premise, nessun dato esce dall'infrastruttura
- **Costi Zero**: Utilizzo di tecnologie open source (Ollama/Mistral)
- **ScalabilitÃ **: Architettura modulare facilmente estendibile

## ğŸš€ Quick Start

### Prerequisiti
- Docker e Docker Compose installati
- Ollama installato sulla macchina host
- 8GB RAM minimo consigliato

### Installazione


1. **Installa e avvia Ollama** (sulla macchina host, NON nel container)
```bash
# Su macOS
brew install ollama
ollama serve

# Su Linux
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
```

2. **Scarica il modello Mistral**
```bash
ollama pull mistral
```

3. **Avvia i container Docker**
```bash
docker-compose up --build
```


## ğŸ“ Struttura Progetto

```
chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # Entry point FastAPI
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chatbot.py          # Endpoint principale
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ db_loader.py        # Caricamento dati
â”‚   â”‚   â”œâ”€â”€ memory.py           # Gestione memoria conversazione
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py   # Costruzione prompt
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py # Classificazione intent
â”‚   â”‚   â”œâ”€â”€ response_cache.py   # Cache risposte
â”‚   â”‚   â”œâ”€â”€ analytics.py        # Sistema analytics
â”‚   â”‚   â””â”€â”€ suggestions.py      # Generazione suggerimenti
â”‚   â”œâ”€â”€ dati_sanitari.json      # Database strutture
â”‚   â”œâ”€â”€ requirements.txt        # Dipendenze Python
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Homepage
â”‚   â”œâ”€â”€ chatbot.html           # Widget chat
â”‚   â”œâ”€â”€ app.js                 # Logica frontend
â”‚   â”œâ”€â”€ style.css              # Stili personalizzati
â”‚   â”œâ”€â”€ nginx.conf             # Config nginx
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ analytics/                  # Directory per log analytics
â”œâ”€â”€ docker-compose.yml         # Orchestrazione container
â””â”€â”€ README.md
```

## ğŸ”§ Architettura Tecnica

### Backend (FastAPI + Ollama)
- **FastAPI**: Framework web moderno e veloce
- **Ollama + Mistral**: LLM locale per privacy garantita
- **Intent Classification**: Identifica il tipo di richiesta
- **Context Memory**: Mantiene il contesto della conversazione
- **Response Cache**: Ottimizza performance per domande frequenti
- **Fuzzy Search**: Trova strutture rilevanti

### Frontend (HTML + Tailwind CSS + Vanilla JS)
- **Responsive Design**: Ottimizzato per tutti i dispositivi
- **Accessibility First**: Font grandi, alto contrasto, navigazione tastiera
- **Voice I/O**: Input e output vocale per accessibilitÃ 
- **Real-time Feedback**: Indicatori di stato e suggerimenti

## ğŸŒŸ FunzionalitÃ  Principali

### Per gli Utenti
- âœ… Ricerca informazioni su ospedali e ambulatori
- âœ… Orari di apertura e servizi disponibili
- âœ… Informazioni per prenotazioni
- âœ… Numeri di telefono e contatti
- âœ… Indicazioni stradali e mappe
- âœ… Input/Output vocale
- âœ… Suggerimenti domande follow-up
- âœ… Interfaccia accessibile per anziani

### Per gli Amministratori
- ğŸ“Š Analytics delle query
- ğŸ” Classificazione intent automatica
- ğŸ’¾ Cache intelligente
- ğŸ“ˆ Metriche performance
- ğŸ” Privacy garantita (tutto on-premise)

## ğŸ“Š Analytics e Monitoraggio

Il sistema raccoglie metriche anonime per migliorare il servizio:

- **Query piÃ¹ frequenti**: Identifica le necessitÃ  degli utenti
- **Tempi di risposta**: Monitora le performance
- **Intent distribution**: Capisce i tipi di richieste
- **Success rate**: Valuta l'efficacia delle risposte

Accedi alle statistiche: `GET http://localhost:8000/api/stats`

## ğŸ” Privacy e Sicurezza

- **Nessuna API esterna**: Tutto gira localmente
- **Dati anonimi**: Nessun dato personale salvato
- **On-premise**: Deployabile su infrastruttura
- **Open Source**: Codice ispezionabile e verificabile


### Tecnologie utilizzate
- [FastAPI](https://fastapi.tiangolo.com/)
- [Ollama](https://ollama.ai/)
- [Mistral AI](https://mistral.ai/)
- [Tailwind CSS](https://tailwindcss.com/)
- [Docker](https://www.docker.com/)
